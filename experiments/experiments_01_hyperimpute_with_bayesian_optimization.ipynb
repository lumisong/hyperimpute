{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "enable_reproducible_results()\n",
    "\n",
    "imputers = Imputers()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_imputer():\n",
    "    return imputers.get(\"hyperimpute\", optimizer=\"bayesian\")\n",
    "\n",
    "\n",
    "def save_results(fname, results):\n",
    "    path = Path(\"experiments_01_hyperimpute_with_bayesian_optimization\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out = path / fname\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "\n",
    "def evaluate_dataset_repeated(\n",
    "    name,\n",
    "    X_raw,\n",
    "    y,\n",
    "    ref_methods=[\n",
    "        \"mean\",\n",
    "        \"sklearn_missforest\",\n",
    "        \"sklearn_ice\",\n",
    "        \"gain\",\n",
    "        \"sinkhorn\",\n",
    "        \"softimpute\",\n",
    "    ],\n",
    "    scenarios=[\"MNAR\", \"MCAR\", \"MAR\"],\n",
    "    miss_pct=[0.1, 0.3, 0.5, 0.7],\n",
    "    n_iter=10,\n",
    "):\n",
    "    results = compare_models(\n",
    "        name=name,\n",
    "        evaluated_model=get_imputer(),\n",
    "        X_raw=X_raw,\n",
    "        ref_methods=ref_methods,\n",
    "        scenarios=scenarios,\n",
    "        miss_pct=miss_pct,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "\n",
    "    save_results(name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check in  debug mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-11T06:53:23.202168+0800][23904][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2024-03-11T06:54:03.997161+0800][23904][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T06:54:03.998159+0800][23904][INFO]   > Imputation iter 0\n",
      "[2024-03-11T06:54:04.548606+0800][23904][INFO] [Evaluate 2] previous config new score = 0.4798893076971098. old score = -9999999\n",
      "[2024-03-11T06:54:13.480351+0800][23904][INFO]      >>> Column 2 <-- score 0.7201745788014966 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:13.900348+0800][23904][INFO] [Evaluate 1] previous config new score = 0.6810132097042186. old score = -9999999\n",
      "[2024-03-11T06:54:19.381023+0800][23904][INFO]      >>> Column 1 <-- score 0.7466934019095612 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:19.566025+0800][23904][INFO]   > Imputation iter 1\n",
      "[2024-03-11T06:54:19.664023+0800][23904][INFO] [Evaluate 2] previous config new score = 0.9743061846665817. old score = 0.7201745788014966\n",
      "[2024-03-11T06:54:24.962465+0800][23904][INFO]      >>> Column 2 <-- score 0.9743061846665817 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:25.401284+0800][23904][INFO] [Evaluate 0] previous config new score = 0.17139808123007266. old score = -9999999\n",
      "[2024-03-11T06:54:30.172187+0800][23904][INFO]      >>> Column 0 <-- score 0.17139808123007266 <-- Model random_forest_regressor({})\n",
      "[2024-03-11T06:54:30.455835+0800][23904][INFO] [Evaluate 1] previous config new score = 0.9886665693104586. old score = 0.7466934019095612\n",
      "[2024-03-11T06:54:36.232135+0800][23904][INFO]      >>> Column 1 <-- score 0.9886665693104586 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:36.377738+0800][23904][INFO]   > Imputation iter 2\n",
      "[2024-03-11T06:54:36.776740+0800][23904][INFO] [Evaluate 0] previous config new score = 0.17604751783708195. old score = 0.17139808123007266\n",
      "[2024-03-11T06:54:41.875678+0800][23904][INFO]      >>> Column 0 <-- score 0.17604751783708195 <-- Model random_forest_regressor({})\n",
      "[2024-03-11T06:54:42.166678+0800][23904][INFO] [Evaluate 2] previous config new score = 0.9883613008594679. old score = 0.9743061846665817\n",
      "[2024-03-11T06:54:47.118876+0800][23904][INFO]      >>> Column 2 <-- score 0.9883613008594679 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:47.561088+0800][23904][INFO] [Evaluate 3] previous config new score = 0.26189102033481504. old score = -9999999\n",
      "[2024-03-11T06:54:53.007128+0800][23904][INFO]      >>> Column 3 <-- score 0.6359577442499608 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:53.163214+0800][23904][INFO]   > Imputation iter 3\n",
      "[2024-03-11T06:54:53.275216+0800][23904][INFO] [Evaluate 3] previous config new score = 0.6727707769789479. old score = 0.6359577442499608\n",
      "[2024-03-11T06:54:58.484553+0800][23904][INFO]      >>> Column 3 <-- score 0.6727707769789479 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:54:58.943379+0800][23904][INFO] [Evaluate 0] previous config new score = 0.17550298950814353. old score = 0.17604751783708195\n",
      "[2024-03-11T06:55:03.428353+0800][23904][INFO]      >>> Column 0 <-- score 0.17550298950814353 <-- Model random_forest_regressor({})\n",
      "[2024-03-11T06:55:03.711349+0800][23904][INFO] [Evaluate 1] previous config new score = 0.9934640850706364. old score = 0.9886665693104586\n",
      "[2024-03-11T06:55:08.243725+0800][23904][INFO]      >>> Column 1 <-- score 0.9934640850706364 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:08.384293+0800][23904][INFO]   > Imputation iter 4\n",
      "[2024-03-11T06:55:08.784293+0800][23904][INFO] [Evaluate 0] previous config new score = 0.16605150123554757. old score = 0.17550298950814353\n",
      "[2024-03-11T06:55:09.464219+0800][23904][INFO]      >>> Column 0 <-- score 0.1749816050343051 <-- Model random_forest_regressor({'criterion': 2, 'max_features': 1, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 3, 'n_estimators': 260})\n",
      "[2024-03-11T06:55:10.288902+0800][23904][INFO] [Evaluate 4] previous config new score = 0.8575452446564713. old score = -9999999\n",
      "[2024-03-11T06:55:14.232326+0800][23904][INFO]      >>> Column 4 <-- score 0.9939769776857098 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:14.369884+0800][23904][INFO] [Evaluate 2] previous config new score = 0.9837660152991703. old score = 0.9883613008594679\n",
      "[2024-03-11T06:55:19.402886+0800][23904][INFO]      >>> Column 2 <-- score 0.9837660152991703 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:19.645383+0800][23904][INFO]   > Imputation iter 5\n",
      "[2024-03-11T06:55:19.737383+0800][23904][INFO] [Evaluate 4] previous config new score = 0.9952121311180635. old score = 0.9939769776857098\n",
      "[2024-03-11T06:55:24.680872+0800][23904][INFO]      >>> Column 4 <-- score 0.9952121311180635 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:24.816870+0800][23904][INFO] [Evaluate 1] previous config new score = 0.9916208526747565. old score = 0.9934640850706364\n",
      "[2024-03-11T06:55:29.928727+0800][23904][INFO]      >>> Column 1 <-- score 0.9916208526747565 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:30.114496+0800][23904][INFO]   > Imputation iter 6\n",
      "[2024-03-11T06:55:30.224496+0800][23904][INFO] [Evaluate 1] previous config new score = 0.9939185795129046. old score = 0.9916208526747565\n",
      "[2024-03-11T06:55:35.742580+0800][23904][INFO]      >>> Column 1 <-- score 0.9939185795129046 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:35.877577+0800][23904][INFO] [Evaluate 4] previous config new score = 0.9949288283826714. old score = 0.9952121311180635\n",
      "[2024-03-11T06:55:40.081427+0800][23904][INFO]      >>> Column 4 <-- score 0.9949288283826714 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:40.268426+0800][23904][INFO]   > Imputation iter 7\n",
      "[2024-03-11T06:55:40.373014+0800][23904][INFO] [Evaluate 3] previous config new score = 0.6792967283885505. old score = 0.6727707769789479\n",
      "[2024-03-11T06:55:41.945389+0800][23904][INFO]      >>> Column 3 <-- score 0.6792967283885505 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:42.086387+0800][23904][INFO] [Evaluate 1] previous config new score = 0.994699161975322. old score = 0.9939185795129046\n",
      "[2024-03-11T06:55:47.285534+0800][23904][INFO]      >>> Column 1 <-- score 0.994699161975322 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:47.475174+0800][23904][INFO]   > Imputation iter 8\n",
      "[2024-03-11T06:55:47.589013+0800][23904][INFO] [Evaluate 3] previous config new score = 0.6886356313097735. old score = 0.6792967283885505\n",
      "[2024-03-11T06:55:49.114798+0800][23904][INFO]      >>> Column 3 <-- score 0.6886356313097735 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:49.251795+0800][23904][INFO] [Evaluate 4] previous config new score = 0.9950444014931924. old score = 0.9949288283826714\n",
      "[2024-03-11T06:55:50.842147+0800][23904][INFO]      >>> Column 4 <-- score 0.9950444014931924 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:51.021144+0800][23904][INFO]   > Imputation iter 9\n",
      "[2024-03-11T06:55:51.116849+0800][23904][INFO] [Evaluate 1] previous config new score = 0.9911056009507189. old score = 0.994699161975322\n",
      "[2024-03-11T06:55:56.429907+0800][23904][INFO]      >>> Column 1 <-- score 0.9911056009507189 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:56.580426+0800][23904][INFO] [Evaluate 4] previous config new score = 0.9903958514738727. old score = 0.9950444014931924\n",
      "[2024-03-11T06:55:58.016451+0800][23904][INFO]      >>> Column 4 <-- score 0.9903958514738727 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:55:58.210051+0800][23904][INFO]   > Imputation iter 10\n",
      "[2024-03-11T06:55:59.116237+0800][23904][INFO] [Evaluate 0] previous config new score = 0.1421561808501553. old score = 0.1749816050343051\n",
      "[2024-03-11T06:55:59.794424+0800][23904][INFO]      >>> Column 0 <-- score 0.1749816050343051 <-- Model random_forest_regressor({'criterion': 2, 'max_features': 1, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 3, 'n_estimators': 260})\n",
      "[2024-03-11T06:56:00.312001+0800][23904][INFO] [Evaluate 3] previous config new score = 0.6836340323229931. old score = 0.6886356313097735\n",
      "[2024-03-11T06:56:01.699663+0800][23904][INFO]      >>> Column 3 <-- score 0.6836340323229931 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:56:01.835661+0800][23904][INFO] [Evaluate 4] previous config new score = 0.9886423853854658. old score = 0.9903958514738727\n",
      "[2024-03-11T06:56:05.988023+0800][23904][INFO]      >>> Column 4 <-- score 0.9886423853854658 <-- Model xgboost_regressor({})\n",
      "[2024-03-11T06:56:06.157434+0800][23904][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T06:56:06.160431+0800][23904][INFO] benchmark hyperimpute took 162.81725978851318\n",
      "[2024-03-11T06:56:06.170432+0800][23904][INFO] benchmark mean took 0.0039980411529541016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Desktop\\插补实验\\hyperimpute\\hyperimpute\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "RMSE score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>mean</th>\n",
       "      <th>miracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2008 +/- 0.0</td>\n",
       "      <td>0.2913 +/- 0.0</td>\n",
       "      <td>0.2843 +/- 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute            mean  \\\n",
       "0     MNAR              0.3         0.2008 +/- 0.0  0.2913 +/- 0.0   \n",
       "\n",
       "          miracle  \n",
       "0  0.2843 +/- 0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "\n",
      "Wasserstein score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>mean</th>\n",
       "      <th>miracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0943 +/- 0.0</td>\n",
       "      <td>0.3687 +/- 0.0</td>\n",
       "      <td>0.2493 +/- 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute            mean  \\\n",
       "0     MNAR              0.3         0.0943 +/- 0.0  0.3687 +/- 0.0   \n",
       "\n",
       "          miracle  \n",
       "0  0.2493 +/- 0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "y = df[5]\n",
    "X_raw = df.drop(columns=[5])\n",
    "\n",
    "evaluate_dataset_repeated(\n",
    "    \"airfoil_debug\",\n",
    "    X_raw,\n",
    "    y,\n",
    "    scenarios=[\"MNAR\"],\n",
    "    ref_methods=[\"mean\", \"miracle\"],\n",
    "    n_iter=1,\n",
    "    miss_pct=[0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperimpute.logger as log\n",
    "\n",
    "log.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset     | Length | Features |\n",
    "|-------------|--------|----------|\n",
    "| airfoil     | 1503   | 6        |\n",
    "| blood       | 748    | 5        |\n",
    "| bc          | 569    | 30       |\n",
    "| california  | 20640  | 8        |\n",
    "| climate     | 540    | 21       |\n",
    "| compression | 1030   | 9        |\n",
    "| slump       | 103    | 11       |\n",
    "| sonar       | 208    | 61       |\n",
    "| diabetes    | 442    | 10       |\n",
    "| wine_red    | 1599   | 12       |\n",
    "| wine_white  | 4898   | 12       |\n",
    "| yeast       | 1484   | 10       |\n",
    "| iris        | 150    | 4        |\n",
    "| libras      | 360    | 91       |\n",
    "| parkinsons  | 195    | 24       |\n",
    "| yacht       | 308    | 7        |\n",
    "| ionosphere  | 351    | 35       |\n",
    "| letter      | 20000  | 17       |\n",
    "| spam        | 4600   | 58       |\n",
    "| credit      | 690    | 16       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: UCI Airfoil Self-Noise Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2500</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>110.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3150</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>109.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>4000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>6300</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>104.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1       2     3         4        5\n",
       "0      800   0.0  0.3048  71.3  0.002663  126.201\n",
       "1     1000   0.0  0.3048  71.3  0.002663  125.201\n",
       "2     1250   0.0  0.3048  71.3  0.002663  125.951\n",
       "3     1600   0.0  0.3048  71.3  0.002663  127.591\n",
       "4     2000   0.0  0.3048  71.3  0.002663  127.461\n",
       "...    ...   ...     ...   ...       ...      ...\n",
       "1498  2500  15.6  0.1016  39.6  0.052849  110.264\n",
       "1499  3150  15.6  0.1016  39.6  0.052849  109.254\n",
       "1500  4000  15.6  0.1016  39.6  0.052849  106.604\n",
       "1501  5000  15.6  0.1016  39.6  0.052849  106.224\n",
       "1502  6300  15.6  0.1016  39.6  0.052849  104.204\n",
       "\n",
       "[1503 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"airfoil\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: UCI Blood Transfusion Service Center Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"blood\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X_raw, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"bc\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: California Housing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X_raw, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"california\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Climate Model Simulation Crashes\n",
    "https://archive.ics.uci.edu/ml/datasets/climate+model+simulation+crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "df = pd.DataFrame(samples)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"climate\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Compressive Strength Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"compression\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Slump Test Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/concrete+slump+test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[\"No\", last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"slump\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectionist Bench (Sonar, Mines vs. Rocks) Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = (df[last_col] == \"M\").astype(int)\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"sonar\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-Red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Data Set\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_red\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-White dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_white\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d336729",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"diabetes\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"iris\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"ionosphere\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"libras\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df = df.drop(columns=[\"name\"])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"parkinsons\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",\n",
    "    sep=\"\\s+\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"yacht\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"spam\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"letter\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"credit\", X_raw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
