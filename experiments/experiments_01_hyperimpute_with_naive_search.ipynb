{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "enable_reproducible_results()\n",
    "\n",
    "imputers = Imputers()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_naive_search\"\n",
    "\n",
    "\n",
    "def get_imputer():\n",
    "    return imputers.get(\"hyperimpute\", optimizer=\"simple\")\n",
    "\n",
    "\n",
    "def save_results(fname, results):\n",
    "    path = Path(experiment)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out = path / fname\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "\n",
    "def evaluate_dataset_repeated(\n",
    "    name,\n",
    "    X_raw,\n",
    "    y,\n",
    "    ref_methods=[\n",
    "        \"mean\",\n",
    "        \"sklearn_ice\",\n",
    "        \"sklearn_missforest\",\n",
    "        \"softimpute\",\n",
    "        \"gain\",\n",
    "        \"miwae\",\n",
    "        \"sinkhorn\",\n",
    "    ],\n",
    "    scenarios=[\"MAR\", \"MCAR\", \"MNAR\"],\n",
    "    miss_pct=[0.1, 0.3, 0.5, 0.7],\n",
    "    n_iter=10,\n",
    "):\n",
    "    results = compare_models(\n",
    "        name=name,\n",
    "        evaluated_model=get_imputer(),\n",
    "        X_raw=X_raw,\n",
    "        ref_methods=ref_methods,\n",
    "        scenarios=scenarios,\n",
    "        miss_pct=miss_pct,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "\n",
    "    save_results(name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check in  debug mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-11T07:08:05.864552+0800][21032][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2024-03-11T07:08:06.079721+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:08:06.081720+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:08:08.676197+0800][21032][INFO]      >>> Column 1 <-- score 0.9996566481387175 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:09.761332+0800][21032][INFO]      >>> Column 0 <-- score 0.14275775132160595 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:11.225756+0800][21032][INFO]      >>> Column 3 <-- score 0.8816665681674609 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:11.438641+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:08:12.176796+0800][21032][INFO]      >>> Column 0 <-- score 0.15578369037350231 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:13.493914+0800][21032][INFO]      >>> Column 1 <-- score 0.9996752680283194 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:14.476800+0800][21032][INFO]      >>> Column 3 <-- score 0.8816665681674609 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:14.585799+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:08:15.450421+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:16.446444+0800][21032][INFO]      >>> Column 3 <-- score 0.8816665681674609 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:17.395948+0800][21032][INFO]      >>> Column 1 <-- score 0.9996752680283194 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:17.481941+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:08:18.189757+0800][21032][INFO]      >>> Column 3 <-- score 0.8834110552791916 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:19.075465+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:20.062383+0800][21032][INFO]      >>> Column 1 <-- score 0.9996752680283194 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:20.126381+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:08:20.929109+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:22.002401+0800][21032][INFO]      >>> Column 1 <-- score 0.9996752680283194 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:22.848841+0800][21032][INFO]      >>> Column 3 <-- score 0.8834110552791916 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:22.928841+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:08:23.728384+0800][21032][INFO]      >>> Column 1 <-- score 0.9997024691129149 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:24.531100+0800][21032][INFO]      >>> Column 3 <-- score 0.8834110552791916 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:24.651100+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:08:25.469353+0800][21032][INFO]      >>> Column 1 <-- score 0.9997331811883161 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:26.460994+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:27.435892+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:27.541893+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:08:28.894645+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:29.733048+0800][21032][INFO]      >>> Column 1 <-- score 0.9997331811883161 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:29.875048+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:08:30.608687+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:31.401231+0800][21032][INFO]      >>> Column 1 <-- score 0.9997331811883161 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:31.514235+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:08:32.197909+0800][21032][INFO]      >>> Column 1 <-- score 0.9997331811883161 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:32.936480+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:33.842167+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:33.901168+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:08:34.585327+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:35.527588+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:36.294266+0800][21032][INFO]      >>> Column 1 <-- score 0.9997331811883161 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:36.361265+0800][21032][INFO]   > Imputation iter 11\n",
      "[2024-03-11T07:08:37.047484+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:37.892138+0800][21032][INFO]      >>> Column 1 <-- score 0.9997422599940246 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:38.028849+0800][21032][INFO]   > Imputation iter 12\n",
      "[2024-03-11T07:08:38.700448+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:39.414980+0800][21032][INFO]      >>> Column 0 <-- score 0.15849775065398553 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:40.328103+0800][21032][INFO]      >>> Column 1 <-- score 0.9997871457998482 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:40.379710+0800][21032][INFO]   > Imputation iter 13\n",
      "[2024-03-11T07:08:41.067133+0800][21032][INFO]      >>> Column 0 <-- score 0.159235240003206 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:42.375391+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:43.208711+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:43.269711+0800][21032][INFO]   > Imputation iter 14\n",
      "[2024-03-11T07:08:43.969409+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:44.741584+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:44.855583+0800][21032][INFO]   > Imputation iter 15\n",
      "[2024-03-11T07:08:45.538236+0800][21032][INFO]      >>> Column 0 <-- score 0.159235240003206 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:46.438477+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:47.224865+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:47.282863+0800][21032][INFO]   > Imputation iter 16\n",
      "[2024-03-11T07:08:47.970446+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:48.735940+0800][21032][INFO]      >>> Column 0 <-- score 0.159235240003206 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:49.641675+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:49.709676+0800][21032][INFO]   > Imputation iter 17\n",
      "[2024-03-11T07:08:50.382056+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:51.202075+0800][21032][INFO]      >>> Column 0 <-- score 0.159235240003206 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:52.098678+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:52.162678+0800][21032][INFO]   > Imputation iter 18\n",
      "[2024-03-11T07:08:52.816257+0800][21032][INFO]      >>> Column 0 <-- score 0.159235240003206 <-- Model random_forest_regressor\n",
      "[2024-03-11T07:08:53.686028+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:54.444316+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:54.509311+0800][21032][INFO]   > Imputation iter 19\n",
      "[2024-03-11T07:08:55.197662+0800][21032][INFO]      >>> Column 1 <-- score 0.9997995548424061 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:56.024392+0800][21032][INFO]      >>> Column 3 <-- score 0.8852656438250333 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:56.138042+0800][21032][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T07:08:56.143044+0800][21032][INFO] benchmark hyperimpute took 50.09232211112976\n",
      "[2024-03-11T07:08:56.155043+0800][21032][INFO] benchmark mean took 0.006001949310302734\n",
      "[2024-03-11T07:08:56.197041+0800][21032][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2024-03-11T07:08:56.222045+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:08:56.223042+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:08:56.253041+0800][21032][INFO]      >>> Column 0 <-- score 0.10109764495918983 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.292043+0800][21032][INFO]      >>> Column 1 <-- score 0.731582389377111 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.312044+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:08:56.340043+0800][21032][INFO]      >>> Column 0 <-- score 0.14451965281349555 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.378640+0800][21032][INFO]      >>> Column 1 <-- score 0.7440735453684225 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.402638+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:08:56.436639+0800][21032][INFO]      >>> Column 0 <-- score 0.14993779669779816 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.477159+0800][21032][INFO]      >>> Column 1 <-- score 0.7448722285161699 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.499162+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:08:56.528161+0800][21032][INFO]      >>> Column 0 <-- score 0.15025833295964913 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.566158+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.588161+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:08:56.615159+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.657163+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.682161+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:08:56.717159+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.761158+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.783160+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:08:56.814158+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.856161+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.881158+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:08:56.910160+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.957864+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:56.983864+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:08:57.013862+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.057819+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.081818+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:08:57.111820+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.152820+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.177821+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:08:57.210127+0800][21032][INFO]      >>> Column 0 <-- score 0.15026955922168234 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.254131+0800][21032][INFO]      >>> Column 1 <-- score 0.7448928084969053 <-- Model linear_regression\n",
      "[2024-03-11T07:08:57.279131+0800][21032][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T07:08:57.283130+0800][21032][INFO] benchmark ice took 1.0790870189666748\n",
      "[2024-03-11T07:08:57.422707+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:08:57.424707+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:08:58.098392+0800][21032][INFO]      >>> Column 2 <-- score 0.9438875241238527 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:58.821566+0800][21032][INFO]      >>> Column 3 <-- score 0.8271294424616322 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:08:58.938500+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:08:59.622719+0800][21032][INFO]      >>> Column 2 <-- score 0.9962254332135589 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:00.427934+0800][21032][INFO]      >>> Column 3 <-- score 0.8276459543147956 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:00.554933+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:09:01.248993+0800][21032][INFO]      >>> Column 3 <-- score 0.851132056534212 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:02.085871+0800][21032][INFO]      >>> Column 1 <-- score 0.99832266851221 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:02.228869+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:09:02.873605+0800][21032][INFO]      >>> Column 1 <-- score 0.99832266851221 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:03.584505+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:03.691517+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:09:04.491435+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:05.224769+0800][21032][INFO]      >>> Column 1 <-- score 0.99832266851221 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:05.348766+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:09:06.077968+0800][21032][INFO]      >>> Column 2 <-- score 0.9962254332135589 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:06.870573+0800][21032][INFO]      >>> Column 1 <-- score 0.99832266851221 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:06.981155+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:09:07.684516+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:08.402802+0800][21032][INFO]      >>> Column 1 <-- score 0.99832266851221 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:08.510803+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:09:09.227162+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:09.981938+0800][21032][INFO]      >>> Column 2 <-- score 0.9966087926519099 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:10.105546+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:09:10.780197+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:11.609120+0800][21032][INFO]      >>> Column 2 <-- score 0.9966087926519099 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:11.750119+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:09:12.451381+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:13.270494+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:13.407750+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:09:14.152312+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:14.852895+0800][21032][INFO]      >>> Column 2 <-- score 0.9966087926519099 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:14.966894+0800][21032][INFO]   > Imputation iter 11\n",
      "[2024-03-11T07:09:15.675493+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:16.464602+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:16.574601+0800][21032][INFO]   > Imputation iter 12\n",
      "[2024-03-11T07:09:17.281776+0800][21032][INFO]      >>> Column 2 <-- score 0.9967752995581198 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:18.080681+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:18.212679+0800][21032][INFO]   > Imputation iter 13\n",
      "[2024-03-11T07:09:18.910248+0800][21032][INFO]      >>> Column 2 <-- score 0.9967752995581198 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:19.717450+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:19.858449+0800][21032][INFO]   > Imputation iter 14\n",
      "[2024-03-11T07:09:20.552048+0800][21032][INFO]      >>> Column 2 <-- score 0.9967752995581198 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:21.310357+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:21.420926+0800][21032][INFO]   > Imputation iter 15\n",
      "[2024-03-11T07:09:22.181406+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:22.959964+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:23.079159+0800][21032][INFO]   > Imputation iter 16\n",
      "[2024-03-11T07:09:23.750728+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:24.508203+0800][21032][INFO]      >>> Column 1 <-- score 0.9984253269918841 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:24.623202+0800][21032][INFO]   > Imputation iter 17\n",
      "[2024-03-11T07:09:25.292369+0800][21032][INFO]      >>> Column 1 <-- score 0.9984892277743771 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:26.003042+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:26.105717+0800][21032][INFO]   > Imputation iter 18\n",
      "[2024-03-11T07:09:26.804425+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:27.524878+0800][21032][INFO]      >>> Column 1 <-- score 0.9984892277743771 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:27.639878+0800][21032][INFO]   > Imputation iter 19\n",
      "[2024-03-11T07:09:28.356879+0800][21032][INFO]      >>> Column 1 <-- score 0.9984892277743771 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:29.127918+0800][21032][INFO]      >>> Column 3 <-- score 0.8639922227254783 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:29.269502+0800][21032][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T07:09:29.275499+0800][21032][INFO] benchmark hyperimpute took 31.869791746139526\n",
      "[2024-03-11T07:09:29.290502+0800][21032][INFO] benchmark mean took 0.008002281188964844\n",
      "[2024-03-11T07:09:29.306501+0800][21032][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2024-03-11T07:09:29.338501+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:09:29.339501+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:09:29.374499+0800][21032][INFO]      >>> Column 1 <-- score 0.7035695929900366 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.418173+0800][21032][INFO]      >>> Column 2 <-- score 0.39877632545178726 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.445174+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:09:29.477702+0800][21032][INFO]      >>> Column 1 <-- score 0.7786521868087609 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.516701+0800][21032][INFO]      >>> Column 2 <-- score 0.42188819008038037 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.542701+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:09:29.571704+0800][21032][INFO]      >>> Column 1 <-- score 0.7805788033350946 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.612704+0800][21032][INFO]      >>> Column 2 <-- score 0.422842847979625 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.635704+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:09:29.665703+0800][21032][INFO]      >>> Column 1 <-- score 0.7808655918589191 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.705702+0800][21032][INFO]      >>> Column 2 <-- score 0.4229688311129278 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.727703+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:09:29.752702+0800][21032][INFO]      >>> Column 1 <-- score 0.780923133238175 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.790704+0800][21032][INFO]      >>> Column 2 <-- score 0.42299037843705795 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.816703+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:09:29.845701+0800][21032][INFO]      >>> Column 1 <-- score 0.7809394633133724 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.885703+0800][21032][INFO]      >>> Column 2 <-- score 0.4229952447368322 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.908703+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:09:29.934702+0800][21032][INFO]      >>> Column 1 <-- score 0.7809452548585554 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.967702+0800][21032][INFO]      >>> Column 2 <-- score 0.42299670527908567 <-- Model linear_regression\n",
      "[2024-03-11T07:09:29.990705+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:09:30.023704+0800][21032][INFO]      >>> Column 1 <-- score 0.7809478793487905 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.083490+0800][21032][INFO]      >>> Column 2 <-- score 0.42299723402589645 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.113493+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:09:30.148492+0800][21032][INFO]      >>> Column 1 <-- score 0.7809491237337313 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.190492+0800][21032][INFO]      >>> Column 2 <-- score 0.42299745479385853 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.213492+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:09:30.244491+0800][21032][INFO]      >>> Column 1 <-- score 0.7809497234030782 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.288491+0800][21032][INFO]      >>> Column 2 <-- score 0.4229975527131234 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.310491+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:09:30.335489+0800][21032][INFO]      >>> Column 1 <-- score 0.7809500140482637 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.371492+0800][21032][INFO]      >>> Column 2 <-- score 0.42299759715687335 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.390108+0800][21032][INFO]   > Imputation iter 11\n",
      "[2024-03-11T07:09:30.419104+0800][21032][INFO]      >>> Column 1 <-- score 0.7809501552328464 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.462105+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976174921119 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.480105+0800][21032][INFO]   > Imputation iter 12\n",
      "[2024-03-11T07:09:30.505105+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502238892254 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.543104+0800][21032][INFO]      >>> Column 2 <-- score 0.42299762681822195 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.565104+0800][21032][INFO]   > Imputation iter 13\n",
      "[2024-03-11T07:09:30.591104+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502572988558 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.626106+0800][21032][INFO]      >>> Column 2 <-- score 0.42299763109595717 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.652105+0800][21032][INFO]   > Imputation iter 14\n",
      "[2024-03-11T07:09:30.690107+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502735654572 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.743108+0800][21032][INFO]      >>> Column 2 <-- score 0.42299763305663723 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.769106+0800][21032][INFO]   > Imputation iter 15\n",
      "[2024-03-11T07:09:30.808105+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502814892031 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.849105+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976339542792 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.869104+0800][21032][INFO]   > Imputation iter 16\n",
      "[2024-03-11T07:09:30.896106+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502853507355 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.931106+0800][21032][INFO]      >>> Column 2 <-- score 0.422997634364674 <-- Model linear_regression\n",
      "[2024-03-11T07:09:30.954106+0800][21032][INFO]   > Imputation iter 17\n",
      "[2024-03-11T07:09:30.979107+0800][21032][INFO]      >>> Column 1 <-- score 0.780950287233412 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.018107+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976345520095 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.039106+0800][21032][INFO]   > Imputation iter 18\n",
      "[2024-03-11T07:09:31.067739+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502881516838 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.105508+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976346373755 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.125507+0800][21032][INFO]   > Imputation iter 19\n",
      "[2024-03-11T07:09:31.152508+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502885997479 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.192436+0800][21032][INFO]      >>> Column 2 <-- score 0.42299763467620005 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.214437+0800][21032][INFO]   > Imputation iter 20\n",
      "[2024-03-11T07:09:31.244436+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502888184616 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.286434+0800][21032][INFO]      >>> Column 2 <-- score 0.42299763469381974 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.306434+0800][21032][INFO]   > Imputation iter 21\n",
      "[2024-03-11T07:09:31.339434+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502889252622 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.378023+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976347017971 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.399022+0800][21032][INFO]   > Imputation iter 22\n",
      "[2024-03-11T07:09:31.427025+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502889774329 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.465023+0800][21032][INFO]      >>> Column 2 <-- score 0.42299763470539914 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.485023+0800][21032][INFO]   > Imputation iter 23\n",
      "[2024-03-11T07:09:31.511026+0800][21032][INFO]      >>> Column 1 <-- score 0.7809502890029261 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.547024+0800][21032][INFO]      >>> Column 2 <-- score 0.4229976347070205 <-- Model linear_regression\n",
      "[2024-03-11T07:09:31.572026+0800][21032][INFO]      >>>> Early stopping on imputation diff iteration : 23 err: 8.641764235852358e-20\n",
      "[2024-03-11T07:09:31.575026+0800][21032][INFO] benchmark ice took 2.2605254650115967\n",
      "[2024-03-11T07:09:31.725022+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:09:31.726022+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:09:32.429261+0800][21032][INFO]      >>> Column 2 <-- score 0.9301227917394834 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:33.197492+0800][21032][INFO]      >>> Column 1 <-- score 0.9968058107105093 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:33.352494+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:09:34.053888+0800][21032][INFO]      >>> Column 2 <-- score 0.9942790414485394 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:34.802475+0800][21032][INFO]      >>> Column 3 <-- score 0.8427707819355771 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:34.908478+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:09:35.598507+0800][21032][INFO]      >>> Column 2 <-- score 0.9953449679193436 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:36.310491+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:36.425085+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:09:37.099830+0800][21032][INFO]      >>> Column 2 <-- score 0.9957939892287682 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:37.852973+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:37.968973+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:09:38.664443+0800][21032][INFO]      >>> Column 2 <-- score 0.9957939892287682 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:39.435628+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:39.667627+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:09:40.362289+0800][21032][INFO]      >>> Column 1 <-- score 0.9968058107105093 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:41.139302+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:41.347522+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:09:42.084471+0800][21032][INFO]      >>> Column 2 <-- score 0.9957939892287682 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:42.850083+0800][21032][INFO]      >>> Column 1 <-- score 0.9968058107105093 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:42.957085+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:09:43.646512+0800][21032][INFO]      >>> Column 2 <-- score 0.996069050867807 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:44.431695+0800][21032][INFO]      >>> Column 1 <-- score 0.9968058107105093 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:44.546695+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:09:45.280225+0800][21032][INFO]      >>> Column 2 <-- score 0.996069050867807 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:46.070201+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:46.242324+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:09:46.934942+0800][21032][INFO]      >>> Column 2 <-- score 0.996069050867807 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:47.706736+0800][21032][INFO]      >>> Column 1 <-- score 0.9968058107105093 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:47.824737+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:09:48.724046+0800][21032][INFO]      >>> Column 2 <-- score 0.996069050867807 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:49.531999+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:49.643998+0800][21032][INFO]   > Imputation iter 11\n",
      "[2024-03-11T07:09:50.318581+0800][21032][INFO]      >>> Column 3 <-- score 0.8459457255963558 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:51.064013+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:51.184884+0800][21032][INFO]   > Imputation iter 12\n",
      "[2024-03-11T07:09:51.856575+0800][21032][INFO]      >>> Column 1 <-- score 0.9972122208300058 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:52.580234+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:52.693231+0800][21032][INFO]   > Imputation iter 13\n",
      "[2024-03-11T07:09:53.383860+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:54.152008+0800][21032][INFO]      >>> Column 1 <-- score 0.9973482098754971 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:54.285010+0800][21032][INFO]   > Imputation iter 14\n",
      "[2024-03-11T07:09:54.967762+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:55.747735+0800][21032][INFO]      >>> Column 3 <-- score 0.8460435702346079 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:55.872347+0800][21032][INFO]   > Imputation iter 15\n",
      "[2024-03-11T07:09:56.628342+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:57.440641+0800][21032][INFO]      >>> Column 1 <-- score 0.9973482098754971 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:57.564640+0800][21032][INFO]   > Imputation iter 16\n",
      "[2024-03-11T07:09:58.255771+0800][21032][INFO]      >>> Column 1 <-- score 0.9973482098754971 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:58.974357+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:09:59.084214+0800][21032][INFO]   > Imputation iter 17\n",
      "[2024-03-11T07:09:59.811723+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:00.619529+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:00.751526+0800][21032][INFO]   > Imputation iter 18\n",
      "[2024-03-11T07:10:01.432831+0800][21032][INFO]      >>> Column 3 <-- score 0.8460435702346079 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:02.224266+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:02.350263+0800][21032][INFO]   > Imputation iter 19\n",
      "[2024-03-11T07:10:03.016834+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:03.782693+0800][21032][INFO]      >>> Column 3 <-- score 0.8460435702346079 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:03.973691+0800][21032][INFO]   > Imputation iter 20\n",
      "[2024-03-11T07:10:04.680311+0800][21032][INFO]      >>> Column 3 <-- score 0.8460435702346079 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:05.462087+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:05.574086+0800][21032][INFO]   > Imputation iter 21\n",
      "[2024-03-11T07:10:06.334873+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:07.045223+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:07.152222+0800][21032][INFO]   > Imputation iter 22\n",
      "[2024-03-11T07:10:07.816679+0800][21032][INFO]      >>> Column 3 <-- score 0.8460435702346079 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:08.610345+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:08.735340+0800][21032][INFO]   > Imputation iter 23\n",
      "[2024-03-11T07:10:09.394117+0800][21032][INFO]      >>> Column 1 <-- score 0.9981048238242317 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:10.133025+0800][21032][INFO]      >>> Column 2 <-- score 0.9968877051712075 <-- Model xgboost_regressor\n",
      "[2024-03-11T07:10:10.241024+0800][21032][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T07:10:10.245025+0800][21032][INFO] benchmark hyperimpute took 38.540000438690186\n",
      "[2024-03-11T07:10:10.255027+0800][21032][INFO] benchmark mean took 0.004999399185180664\n",
      "[2024-03-11T07:10:10.269025+0800][21032][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2024-03-11T07:10:10.298026+0800][21032][INFO]   > HyperImpute using inner optimization\n",
      "[2024-03-11T07:10:10.299026+0800][21032][INFO]   > Imputation iter 0\n",
      "[2024-03-11T07:10:10.331025+0800][21032][INFO]      >>> Column 1 <-- score 0.6620289330052207 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.372740+0800][21032][INFO]      >>> Column 2 <-- score 0.3869184423168682 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.393747+0800][21032][INFO]   > Imputation iter 1\n",
      "[2024-03-11T07:10:10.418749+0800][21032][INFO]      >>> Column 1 <-- score 0.7529092504310413 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.473748+0800][21032][INFO]      >>> Column 2 <-- score 0.4143181210610262 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.500750+0800][21032][INFO]   > Imputation iter 2\n",
      "[2024-03-11T07:10:10.536750+0800][21032][INFO]      >>> Column 1 <-- score 0.7545849781013296 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.587749+0800][21032][INFO]      >>> Column 2 <-- score 0.4153554220538212 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.614748+0800][21032][INFO]   > Imputation iter 3\n",
      "[2024-03-11T07:10:10.646751+0800][21032][INFO]      >>> Column 1 <-- score 0.754813288227187 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.691749+0800][21032][INFO]      >>> Column 2 <-- score 0.4155354755870987 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.717747+0800][21032][INFO]   > Imputation iter 4\n",
      "[2024-03-11T07:10:10.749749+0800][21032][INFO]      >>> Column 1 <-- score 0.754848067436628 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.791750+0800][21032][INFO]      >>> Column 2 <-- score 0.4155722129080745 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.812748+0800][21032][INFO]   > Imputation iter 5\n",
      "[2024-03-11T07:10:10.841746+0800][21032][INFO]      >>> Column 1 <-- score 0.7548537136679594 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.880746+0800][21032][INFO]      >>> Column 2 <-- score 0.4155801410992425 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.903746+0800][21032][INFO]   > Imputation iter 6\n",
      "[2024-03-11T07:10:10.933747+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.976749+0800][21032][INFO]      >>> Column 2 <-- score 0.4155819417252658 <-- Model linear_regression\n",
      "[2024-03-11T07:10:10.999747+0800][21032][INFO]   > Imputation iter 7\n",
      "[2024-03-11T07:10:11.031746+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.074475+0800][21032][INFO]      >>> Column 2 <-- score 0.4155823736049095 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.098478+0800][21032][INFO]   > Imputation iter 8\n",
      "[2024-03-11T07:10:11.129476+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.172478+0800][21032][INFO]      >>> Column 2 <-- score 0.4155824815501897 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.194479+0800][21032][INFO]   > Imputation iter 9\n",
      "[2024-03-11T07:10:11.228477+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.356878+0800][21032][INFO]      >>> Column 2 <-- score 0.4155825050691128 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.388544+0800][21032][INFO]   > Imputation iter 10\n",
      "[2024-03-11T07:10:11.415544+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.451543+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.475545+0800][21032][INFO]   > Imputation iter 11\n",
      "[2024-03-11T07:10:11.502542+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.538544+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.557545+0800][21032][INFO]   > Imputation iter 12\n",
      "[2024-03-11T07:10:11.582542+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.626545+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.647542+0800][21032][INFO]   > Imputation iter 13\n",
      "[2024-03-11T07:10:11.677541+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.717544+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.738543+0800][21032][INFO]   > Imputation iter 14\n",
      "[2024-03-11T07:10:11.763541+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.799542+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.818543+0800][21032][INFO]   > Imputation iter 15\n",
      "[2024-03-11T07:10:11.843543+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.881542+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.901541+0800][21032][INFO]   > Imputation iter 16\n",
      "[2024-03-11T07:10:11.931546+0800][21032][INFO]      >>> Column 1 <-- score 0.7548544473684373 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.967542+0800][21032][INFO]      >>> Column 2 <-- score 0.41558250820479564 <-- Model linear_regression\n",
      "[2024-03-11T07:10:11.985542+0800][21032][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2024-03-11T07:10:11.990544+0800][21032][INFO] benchmark ice took 1.7125179767608643\n",
      "[2024-03-11T07:10:11.992543+0800][21032][INFO] benchmark took 126.11699271202087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>mean</th>\n",
       "      <th>ice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1469 +/- 0.023</td>\n",
       "      <td>0.3238 +/- 0.03</td>\n",
       "      <td>0.2867 +/- 0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute             mean  \\\n",
       "0      MAR              0.3       0.1469 +/- 0.023  0.3238 +/- 0.03   \n",
       "\n",
       "                ice  \n",
       "0  0.2867 +/- 0.021  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "\n",
      "Wasserstein score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>miss_pct [0, 1]</th>\n",
       "      <th>Evaluated: hyperimpute</th>\n",
       "      <th>mean</th>\n",
       "      <th>ice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAR</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0362 +/- 0.0043</td>\n",
       "      <td>0.2482 +/- 0.0344</td>\n",
       "      <td>0.1389 +/- 0.0119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario  miss_pct [0, 1] Evaluated: hyperimpute               mean  \\\n",
       "0      MAR              0.3      0.0362 +/- 0.0043  0.2482 +/- 0.0344   \n",
       "\n",
       "                 ice  \n",
       "0  0.1389 +/- 0.0119  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "y = df[5]\n",
    "X_raw = df.drop(columns=[5])\n",
    "\n",
    "evaluate_dataset_repeated(\n",
    "    \"airfoil_debug\",\n",
    "    X_raw,\n",
    "    y,\n",
    "    scenarios=[\"MAR\"],\n",
    "    ref_methods=[\"mean\", \"ice\"],\n",
    "    n_iter=3,\n",
    "    miss_pct=[0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperimpute.logger as log\n",
    "\n",
    "log.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset     | Length | Features |\n",
    "|-------------|--------|----------|\n",
    "| airfoil     | 1503   | 6        |\n",
    "| blood       | 748    | 5        |\n",
    "| bc          | 569    | 30       |\n",
    "| california  | 20640  | 8        |\n",
    "| climate     | 540    | 21       |\n",
    "| compression | 1030   | 9        |\n",
    "| slump       | 103    | 11       |\n",
    "| sonar       | 208    | 61       |\n",
    "| diabetes    | 442    | 10       |\n",
    "| wine_red    | 1599   | 12       |\n",
    "| wine_white  | 4898   | 12       |\n",
    "| yeast       | 1484   | 10       |\n",
    "| iris        | 150    | 4        |\n",
    "| libras      | 360    | 91       |\n",
    "| parkinsons  | 195    | 24       |\n",
    "| yacht       | 308    | 7        |\n",
    "| ionosphere  | 351    | 35       |\n",
    "| letter      | 20000  | 17       |\n",
    "| spam        | 4600   | 58       |\n",
    "| credit      | 690    | 16       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: UCI Airfoil Self-Noise Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2500</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>110.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3150</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>109.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>4000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>6300</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>104.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1       2     3         4        5\n",
       "0      800   0.0  0.3048  71.3  0.002663  126.201\n",
       "1     1000   0.0  0.3048  71.3  0.002663  125.201\n",
       "2     1250   0.0  0.3048  71.3  0.002663  125.951\n",
       "3     1600   0.0  0.3048  71.3  0.002663  127.591\n",
       "4     2000   0.0  0.3048  71.3  0.002663  127.461\n",
       "...    ...   ...     ...   ...       ...      ...\n",
       "1498  2500  15.6  0.1016  39.6  0.052849  110.264\n",
       "1499  3150  15.6  0.1016  39.6  0.052849  109.254\n",
       "1500  4000  15.6  0.1016  39.6  0.052849  106.604\n",
       "1501  5000  15.6  0.1016  39.6  0.052849  106.224\n",
       "1502  6300  15.6  0.1016  39.6  0.052849  104.204\n",
       "\n",
       "[1503 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"airfoil\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X_raw, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"bc\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Compressive Strength Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"compression\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-Red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Data Set\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_red\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-White dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_white\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\",\n",
    "    sep=\"\\s+\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "df = df.drop(columns=[0])\n",
    "\n",
    "for col in [9]:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"yeast\", X_raw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"diabetes\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"iris\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"ionosphere\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"libras\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df = df.drop(columns=[\"name\"])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"parkinsons\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"spam\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"letter\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"credit\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def smooth_line(src: list) -> list:\n",
    "    return signal.savgol_filter(src, 3, 1)\n",
    "\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ),\n",
    "    \"bc\": X_raw_breast_cancer,\n",
    "    \"california\": X_raw_california,\n",
    "    \"climate\": climate_model_df,\n",
    "    \"compression\": pd.read_excel(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    ),\n",
    "    \"slump\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    ),\n",
    "    \"sonar\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"diabetes\": X_raw_diab,\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"libras\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"parkinsons\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "        sep=\",\",\n",
    "    ),\n",
    "    \"yacht\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",\n",
    "        sep=\"\\s+\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"ionosphere\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"letter\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"spam\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "    ),\n",
    "    \"credit\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_naive_search\"\n",
    "results = Path(experiment).glob(\"*\")\n",
    "\n",
    "remap_models = {\n",
    "    \"Our method\": \"hyperimpute\",\n",
    "    \"sklearn_missforest\": \"missforest\",\n",
    "    \"sklearn_ice\": \"ice\",\n",
    "}\n",
    "norm_cols = [\n",
    "    \"Our method\",\n",
    "    \"mean\",\n",
    "    \"sklearn_missforest\",\n",
    "    \"sklearn_ice\",\n",
    "    \"gain\",\n",
    "    \"sinkhorn\",\n",
    "    \"softimpute\",\n",
    "]\n",
    "\n",
    "rmse_key = \"Mean RMSE\"\n",
    "wass_key = \"Mean Wasserstein distance\"\n",
    "pred_key = \"Mean downstream prediction error\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "df_names = [\n",
    "    \"airfoil\",\n",
    "    \"bc\",\n",
    "    \"compression\",\n",
    "    \"diabetes\",\n",
    "    \"ionosphere\",\n",
    "    \"iris\",\n",
    "    \"libras\",\n",
    "    \"letter\",\n",
    "    \"credit\",\n",
    "    \"spam\",\n",
    "    \"parkinsons\",\n",
    "    \"wine_red\",\n",
    "    \"wine_white\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_mean_std(data, headers):\n",
    "    _mean = []\n",
    "    _std = []\n",
    "\n",
    "    for scenario in data:\n",
    "        local_mean = []\n",
    "        local_std = []\n",
    "        for vals in scenario:\n",
    "            if isinstance(vals, list):\n",
    "                local_mean.append(vals[0])\n",
    "                local_std.append(vals[1])\n",
    "            else:\n",
    "                local_mean.append(vals)\n",
    "                local_std.append(vals)\n",
    "        _mean.append(local_mean)\n",
    "        _std.append(local_std)\n",
    "    _mean_df = pd.DataFrame(_mean, columns=headers)\n",
    "    _std_df = pd.DataFrame(_std, columns=headers)\n",
    "\n",
    "    return _mean_df, _std_df\n",
    "\n",
    "\n",
    "for res in results:\n",
    "    if \"debug\" in res.name:\n",
    "        continue\n",
    "\n",
    "    if res.name not in df_names:\n",
    "        continue\n",
    "\n",
    "    with open(res) as f:\n",
    "        local_data = json.load(f)\n",
    "\n",
    "        headers = local_data[\"headers\"]\n",
    "\n",
    "        rmse_mean, rmse_std = generate_mean_std(local_data[\"rmse\"], headers)\n",
    "        distr_mean, distr_std = generate_mean_std(local_data[\"wasserstein\"], headers)\n",
    "\n",
    "    data[res.name] = {\n",
    "        rmse_key: (rmse_mean, rmse_std),\n",
    "        wass_key: (distr_mean, distr_std),\n",
    "    }\n",
    "\n",
    "\n",
    "results = {}\n",
    "models_cnt = len(headers) - 2\n",
    "df_names = sorted(data.keys())\n",
    "\n",
    "for dataset in df_names:\n",
    "    for metric in data[dataset]:\n",
    "        df, df_std = data[dataset][metric]\n",
    "\n",
    "        # Prediction norm\n",
    "        num_df = df._get_numeric_data()\n",
    "        num_df[num_df <= 0] = 1e-6\n",
    "\n",
    "        for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "            if scenario not in results:\n",
    "                results[scenario] = {}\n",
    "\n",
    "            for miss in [0.1, 0.3, 0.5, 0.7]:\n",
    "                if miss not in results[scenario]:\n",
    "                    results[scenario][miss] = {}\n",
    "\n",
    "                local_df = df[df[\"Scenario\"] == scenario].drop(columns=[\"Scenario\"])\n",
    "                local_df = local_df[local_df[\"miss_pct [0, 1]\"] == miss].drop(\n",
    "                    columns=[\"miss_pct [0, 1]\"]\n",
    "                )\n",
    "\n",
    "                local_df = local_df.rename(columns=remap_models)\n",
    "\n",
    "                if len(local_df) == 0:\n",
    "                    continue\n",
    "\n",
    "                local_df_std = df_std[df_std[\"Scenario\"] == scenario].drop(\n",
    "                    columns=[\"Scenario\"]\n",
    "                )\n",
    "                local_df_std = local_df_std[\n",
    "                    local_df_std[\"miss_pct [0, 1]\"] == miss\n",
    "                ].drop(columns=[\"miss_pct [0, 1]\"])\n",
    "\n",
    "                local_df_std = local_df_std.rename(columns=remap_models)\n",
    "\n",
    "                if metric not in results[scenario][miss]:\n",
    "                    results[scenario][miss][metric] = {}\n",
    "                for col in local_df.columns:\n",
    "                    if col not in results[scenario][miss][metric]:\n",
    "                        results[scenario][miss][metric][col] = {\n",
    "                            \"mean\": [],\n",
    "                            \"std\": [],\n",
    "                        }\n",
    "                    results[scenario][miss][metric][col][\"mean\"].append(\n",
    "                        min(local_df[col].values[0], 0.5)\n",
    "                    )\n",
    "                    results[scenario][miss][metric][col][\"std\"].append(\n",
    "                        min(local_df_std[col].values[0], 0.01)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(f\"diagrams_{experiment}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontsize = 14\n",
    "df_graph_len = models_cnt + 1\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, miss, metric):\n",
    "    offset = len(data)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=fontsize)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "    for model in results[scenario][miss][metric]:\n",
    "        pos = [idx + df_graph_len * i * barWidth for i in range(offset)]\n",
    "\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "\n",
    "        mod_mean = results[scenario][miss][metric][model][\"mean\"]\n",
    "        mod_std = results[scenario][miss][metric][model][\"std\"]\n",
    "        if max_val < max(mod_mean):\n",
    "            max_val = max(mod_mean)\n",
    "\n",
    "        ax.bar(\n",
    "            pos,\n",
    "            mod_mean,\n",
    "            yerr=mod_std,\n",
    "            width=barWidth,\n",
    "            label=str(model),\n",
    "            edgecolor=\"k\",\n",
    "        )\n",
    "        idx += barWidth\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        ncol=models_cnt,\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [df_graph_len * r + int(models_cnt / 2) for r in range(offset)],\n",
    "        df_names,\n",
    "        rotation=30,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    ax.set_yticks(np.linspace(0, max_val + 0.1, num=5), fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize + 4)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, miss):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "    metrics = list(results[scenario][miss].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(20, 8))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, miss, metric)\n",
    "\n",
    "    plt.xlabel(f\"{scenario} simulation with {miss} missingness\", fontsize=fontsize)\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "    plt.savefig(output_dir / f\"general_overview_{scenario}_{miss}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for miss in [0.1, 0.3, 0.5]:\n",
    "        generate_plot(scenario, miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by miss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_axis = [0.1, 0.3, 0.5]\n",
    "\n",
    "fontsize = 14\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, metric, df_idx):\n",
    "    offset = len(data)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "\n",
    "    for model in results[scenario][0.1][metric]:\n",
    "\n",
    "        datapoints = []\n",
    "        datapoints_std = []\n",
    "\n",
    "        for miss in results[scenario]:\n",
    "            if metric not in results[scenario][miss]:\n",
    "                continue\n",
    "\n",
    "            local_res = results[scenario][miss][metric][model][\"mean\"][df_idx]\n",
    "            local_res_std = results[scenario][miss][metric][model][\"std\"][df_idx]\n",
    "            datapoints.append(local_res)\n",
    "            datapoints_std.append(local_res_std)\n",
    "\n",
    "        ax.errorbar(\n",
    "            x_axis,\n",
    "            smooth_line(datapoints),\n",
    "            yerr=datapoints_std,\n",
    "            label=str(model),\n",
    "            linewidth=2,\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x_axis, fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, df_idx, df_name):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "\n",
    "    metrics = list(results[scenario][0.1].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(10, 11))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, metric, df_idx)\n",
    "\n",
    "    axs[0].legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.15, 1.27),\n",
    "        ncol=int(models_cnt / 3),\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "    fig.suptitle(f\"{scenario} simulation\", fontsize=fontsize)\n",
    "    plt.savefig(output_dir / f\"error_by_miss_{scenario}_{df_name}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_df = [\"airfoil\", \"compression\", \"letter\", \"wine_white\", \"wine_red\"]\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for idx, df_name in enumerate(df_names):\n",
    "        if df_name not in plot_df:\n",
    "            continue\n",
    "        print(\"dataset \", df_name)\n",
    "        generate_plot(scenario, idx, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
