{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants.py\n",
    "\n",
    "# 列名\n",
    "COLUMNS = ['DEPT', 'RMN-RMG', 'CAL', 'SP', 'GR', 'HAC', 'BHC', 'DEN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Description: This HDF5 file contains oil well log data collected from various wells in the North Sea region. The data includes measurements of depth, resistivity, caliper, sound velocity, gamma ray, and density, among others. The measurements were taken using a combination of logging tools and techniques, including electrical resistivity logging (ERL), caliper logging, and gamma ray logging. The data has been processed to ensure consistency and accuracy, including normalization and interpolation where necessary. This file is intended for use in geological and geophysical analyses, particularly in the study of oil and gas reservoirs. For any questions or further information, please contact the data provider at [email protected]\n",
      "Reading BHC...\n",
      "BHC: Unit = us/m, Description = 表面声波时差，没有明确单位，可能是微秒每米 (.us/m)，因为与HAC类似\n",
      "Reading CAL...\n",
      "CAL: Unit = cm, Description = 孔隙径，单位为厘米 (.cm)\n",
      "Reading DEN...\n",
      "DEN: Unit = g/cm3, Description = 密度，单位为克/立方厘米 (.g/cm3)\n",
      "Reading DEPT...\n",
      "DEPT: Unit = m, Description = 深度，单位为米 (.M)\n",
      "Reading GR...\n",
      "GR: Unit = API or unitless, Description = 伽马射线，单位未明确指出，但通常伽马射线的单位是API（美国石油学会单位）或者无单位\n",
      "Reading HAC...\n",
      "HAC: Unit = us/m, Description = 声波时差，单位为微秒每米 (.us/m)\n",
      "Reading RMG...\n",
      "RMG: Unit = ohmm, Description = 电阻率，单位为欧姆米 (.ohmm)\n",
      "Reading RMN...\n",
      "RMN: Unit = ohmm, Description = 电阻率，单位为欧姆米 (.ohmm)\n",
      "Reading RMN-RMG...\n",
      "RMN-RMG: Unit = ohmm, Description = 电阻率差值，没有明确单位，但由于是RMN与RMG的差值，其单位应该也是欧姆米 (.ohmm)\n",
      "Reading SP...\n",
      "SP: Unit = mv, Description = 自发电位，单位为毫伏 (.mv)\n",
      "Reading WellName...\n",
      "WellName: Unit = No unit, Description = No description\n",
      "       BHC     CAL    DEN    DEPT       GR      HAC    RMG    RMN  RMN-RMG  \\\n",
      "0  405.716  23.492  2.269  780.60  102.405  402.244  2.260  2.265    0.005   \n",
      "1  404.701  23.453  2.274  780.65  103.093  397.115  2.241  2.281    0.040   \n",
      "2  403.953  23.403  2.284  780.70  102.995  394.872  2.405  2.474    0.069   \n",
      "3  404.434  23.363  2.274  780.75  102.405  397.009  2.598  2.640    0.042   \n",
      "4  405.021  23.333  2.284  780.80  101.128  404.060  2.533  2.538    0.005   \n",
      "\n",
      "        SP WellName  \n",
      "0  121.845       A1  \n",
      "1  121.845       A1  \n",
      "2  121.656       A1  \n",
      "3  121.325       A1  \n",
      "4  120.994       A1  \n"
     ]
    }
   ],
   "source": [
    "# data_read.py\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_h5(filename):\n",
    "    \"\"\"\n",
    "    从.h5文件中读取数据，并返回一个Pandas DataFrame。\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): 包含从文件中读取的数据的DataFrame。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as h5f:\n",
    "        # 获取文件的描述信息\n",
    "        file_description = h5f.attrs.get('file_description', 'No description')\n",
    "        print(f\"File Description: {file_description}\")\n",
    "        \n",
    "        # 初始化一个空的DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # 遍历文件中的所有数据集\n",
    "        for key in h5f.keys():\n",
    "            print(f\"Reading {key}...\")\n",
    "            # 读取数据集\n",
    "            dataset = h5f[key]\n",
    "            # 将数据集添加到DataFrame中\n",
    "            df[key] = dataset[:]\n",
    "            # 打印数据集的单位和描述\n",
    "            unit = dataset.attrs.get('unit', 'No unit')\n",
    "            description = dataset.attrs.get('description', 'No description')\n",
    "            print(f\"{key}: Unit = {unit}, Description = {description}\")\n",
    "        \n",
    "        # 在添加数据集到DataFrame之后，将WellName列中的字节字符串转换为字符串\n",
    "        df['WellName'] = df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "        return df\n",
    "\n",
    "filename = './well_log_daqing.h5'\n",
    "df = load_data_from_h5(filename)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化器：\n",
    "\n",
    "1. standardize\n",
    "2. maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_process.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "# form constants import COLUMNS\n",
    "\n",
    "class DataStandardizer:\n",
    "    \"\"\"\n",
    "    数据标准化类，使用StandardScaler进行标准化。\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = columns\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        拟合标准化器。\n",
    "        \"\"\"\n",
    "        if self.columns is None:\n",
    "            self.columns = df.columns\n",
    "        self.scaler.fit(df[self.columns])\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"  \n",
    "        对数据进行标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before transforming.\")\n",
    "        # 标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.transform(df[self.columns]), columns=self.columns)\n",
    "        # 将标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df):\n",
    "        \"\"\" \n",
    "        对标准化后的数据进行反标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before inverse transforming.\")\n",
    "        # 反标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.inverse_transform(df[self.columns]), columns=self.columns)\n",
    "        # 将反标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"  \n",
    "        保存标准化器。\n",
    "        \"\"\"\n",
    "        joblib.dump(self.scaler, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\" \n",
    "        加载标准化器。\n",
    "        \"\"\"\n",
    "        self.scaler = joblib.load(filename)\n",
    "        self.fitted = True\n",
    "\n",
    "# 示例使用\n",
    "standardizer = DataStandardizer(columns= COLUMNS) # 指定需要标准化的列\n",
    "standardizer.fit(df) # 使用df数据进行标准化\n",
    "df_standardized = standardizer.transform(df) # 标准化df数据\n",
    "\n",
    "# 保存标准化器\n",
    "standardizer.save('scaler.joblib')\n",
    "\n",
    "# # 加载标准化器\n",
    "# standardizer.load('scaler.joblib')\n",
    "\n",
    "# # 反标准化\n",
    "# df_original = standardizer.inverse_transform(df_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHC</th>\n",
       "      <th>CAL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>DEPT</th>\n",
       "      <th>GR</th>\n",
       "      <th>HAC</th>\n",
       "      <th>RMG</th>\n",
       "      <th>RMN</th>\n",
       "      <th>RMN-RMG</th>\n",
       "      <th>SP</th>\n",
       "      <th>WellName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.354331</td>\n",
       "      <td>1.382265</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>-1.575040</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>1.203110</td>\n",
       "      <td>2.260</td>\n",
       "      <td>2.265</td>\n",
       "      <td>-0.687548</td>\n",
       "      <td>1.389699</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.331241</td>\n",
       "      <td>1.345440</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>-1.574611</td>\n",
       "      <td>-0.067284</td>\n",
       "      <td>1.092743</td>\n",
       "      <td>2.241</td>\n",
       "      <td>2.281</td>\n",
       "      <td>-0.658715</td>\n",
       "      <td>1.389699</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.314226</td>\n",
       "      <td>1.298230</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>-1.574182</td>\n",
       "      <td>-0.068630</td>\n",
       "      <td>1.044477</td>\n",
       "      <td>2.405</td>\n",
       "      <td>2.474</td>\n",
       "      <td>-0.634824</td>\n",
       "      <td>1.378332</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.325168</td>\n",
       "      <td>1.260461</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>-1.573753</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>1.090462</td>\n",
       "      <td>2.598</td>\n",
       "      <td>2.640</td>\n",
       "      <td>-0.657067</td>\n",
       "      <td>1.358426</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.338521</td>\n",
       "      <td>1.232135</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>-1.573324</td>\n",
       "      <td>-0.094258</td>\n",
       "      <td>1.242187</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.538</td>\n",
       "      <td>-0.687548</td>\n",
       "      <td>1.338520</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>-0.231540</td>\n",
       "      <td>-0.852690</td>\n",
       "      <td>-1.580308</td>\n",
       "      <td>0.359415</td>\n",
       "      <td>-0.367605</td>\n",
       "      <td>-0.233752</td>\n",
       "      <td>6.191</td>\n",
       "      <td>8.237</td>\n",
       "      <td>0.993849</td>\n",
       "      <td>-1.949959</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38730</th>\n",
       "      <td>-0.282565</td>\n",
       "      <td>-0.881016</td>\n",
       "      <td>-1.287160</td>\n",
       "      <td>0.359844</td>\n",
       "      <td>-0.346479</td>\n",
       "      <td>-0.233752</td>\n",
       "      <td>5.867</td>\n",
       "      <td>8.042</td>\n",
       "      <td>1.100121</td>\n",
       "      <td>-1.953868</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38731</th>\n",
       "      <td>-0.332362</td>\n",
       "      <td>-0.895179</td>\n",
       "      <td>-1.077768</td>\n",
       "      <td>0.360273</td>\n",
       "      <td>-0.320068</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>6.723</td>\n",
       "      <td>9.164</td>\n",
       "      <td>1.319255</td>\n",
       "      <td>-1.959762</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38732</th>\n",
       "      <td>-0.373673</td>\n",
       "      <td>-0.859299</td>\n",
       "      <td>-0.931194</td>\n",
       "      <td>0.360702</td>\n",
       "      <td>-0.279134</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>7.263</td>\n",
       "      <td>9.530</td>\n",
       "      <td>1.175912</td>\n",
       "      <td>-1.953868</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38733</th>\n",
       "      <td>-0.496356</td>\n",
       "      <td>-0.798870</td>\n",
       "      <td>-0.920724</td>\n",
       "      <td>0.361131</td>\n",
       "      <td>-0.248756</td>\n",
       "      <td>-0.587599</td>\n",
       "      <td>6.874</td>\n",
       "      <td>8.828</td>\n",
       "      <td>0.918059</td>\n",
       "      <td>-1.949959</td>\n",
       "      <td>A6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38734 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BHC       CAL       DEN      DEPT        GR       HAC    RMG  \\\n",
       "0      1.354331  1.382265  0.021540 -1.575040 -0.076729  1.203110  2.260   \n",
       "1      1.331241  1.345440  0.073887 -1.574611 -0.067284  1.092743  2.241   \n",
       "2      1.314226  1.298230  0.178583 -1.574182 -0.068630  1.044477  2.405   \n",
       "3      1.325168  1.260461  0.073887 -1.573753 -0.076729  1.090462  2.598   \n",
       "4      1.338521  1.232135  0.178583 -1.573324 -0.094258  1.242187  2.533   \n",
       "...         ...       ...       ...       ...       ...       ...    ...   \n",
       "38729 -0.231540 -0.852690 -1.580308  0.359415 -0.367605 -0.233752  6.191   \n",
       "38730 -0.282565 -0.881016 -1.287160  0.359844 -0.346479 -0.233752  5.867   \n",
       "38731 -0.332362 -0.895179 -1.077768  0.360273 -0.320068 -0.240638  6.723   \n",
       "38732 -0.373673 -0.859299 -0.931194  0.360702 -0.279134 -0.240638  7.263   \n",
       "38733 -0.496356 -0.798870 -0.920724  0.361131 -0.248756 -0.587599  6.874   \n",
       "\n",
       "         RMN   RMN-RMG        SP WellName  \n",
       "0      2.265 -0.687548  1.389699       A1  \n",
       "1      2.281 -0.658715  1.389699       A1  \n",
       "2      2.474 -0.634824  1.378332       A1  \n",
       "3      2.640 -0.657067  1.358426       A1  \n",
       "4      2.538 -0.687548  1.338520       A1  \n",
       "...      ...       ...       ...      ...  \n",
       "38729  8.237  0.993849 -1.949959       A6  \n",
       "38730  8.042  1.100121 -1.953868       A6  \n",
       "38731  9.164  1.319255 -1.959762       A6  \n",
       "38732  9.530  1.175912 -1.953868       A6  \n",
       "38733  8.828  0.918059 -1.949959       A6  \n",
       "\n",
       "[38734 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_save.py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def save_data_to_h5(data, filename, file_description):\n",
    "    \"\"\"\n",
    "    将数据保存为.h5文件，并添加文件的描述信息作为属性。\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame or ndarray): 要保存的数据。\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "    - file_description (str): 整个文件的描述信息。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as h5f:\n",
    "        # 添加整个文件的描述信息作为根组的属性\n",
    "        h5f.attrs['file_description'] = file_description\n",
    "        \n",
    "        # 创建数据集\n",
    "        for key in data.columns:\n",
    "            dataset = h5f.create_dataset(key, data=data[key].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_h5(filename):\n",
    "    \"\"\"\n",
    "    从.h5文件中读取数据和文件描述信息。\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): 文件名，包括路径和扩展名。\n",
    "\n",
    "    Returns:\n",
    "    - data (DataFrame): 从文件中读取的数据。\n",
    "    - file_description (str): 文件的描述信息。\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as h5f:\n",
    "        # 读取文件描述信息\n",
    "        file_description = h5f.attrs.get('file_description', 'No description available')\n",
    "\n",
    "        data = {key: h5f[key][()] for key in h5f.keys()}\n",
    "        # 将数据转换为DataFrame\n",
    "        data_df = pd.DataFrame(data)\n",
    "        \n",
    "        # 在添加数据集到DataFrame之后，将WellName列中的字节字符串转换为字符串\n",
    "        data_df['WellName'] = data_df['WellName'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "        return data_df, file_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为StandardScaler。\n"
     ]
    }
   ],
   "source": [
    "file_description = \"将标准化后的数据保存为.h5文件，以便后续使用。标准化器为StandardScaler。\"\n",
    "save_data_to_h5(df_standardized, 'well_log_daqing_standardized.h5', file_description)\n",
    "print(\"数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为StandardScaler。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Description: 将标准化后的数据保存为.h5文件，以便后续使用。标准化器为StandardScaler。\n",
      "Data:             BHC       CAL       DEN      DEPT        GR       HAC    RMG  \\\n",
      "0      1.354331  1.382265  0.021540 -1.575040 -0.076729  1.203110  2.260   \n",
      "1      1.331241  1.345440  0.073887 -1.574611 -0.067284  1.092743  2.241   \n",
      "2      1.314226  1.298230  0.178583 -1.574182 -0.068630  1.044477  2.405   \n",
      "3      1.325168  1.260461  0.073887 -1.573753 -0.076729  1.090462  2.598   \n",
      "4      1.338521  1.232135  0.178583 -1.573324 -0.094258  1.242187  2.533   \n",
      "...         ...       ...       ...       ...       ...       ...    ...   \n",
      "38729 -0.231540 -0.852690 -1.580308  0.359415 -0.367605 -0.233752  6.191   \n",
      "38730 -0.282565 -0.881016 -1.287160  0.359844 -0.346479 -0.233752  5.867   \n",
      "38731 -0.332362 -0.895179 -1.077768  0.360273 -0.320068 -0.240638  6.723   \n",
      "38732 -0.373673 -0.859299 -0.931194  0.360702 -0.279134 -0.240638  7.263   \n",
      "38733 -0.496356 -0.798870 -0.920724  0.361131 -0.248756 -0.587599  6.874   \n",
      "\n",
      "         RMN   RMN-RMG        SP WellName  \n",
      "0      2.265 -0.687548  1.389699       A1  \n",
      "1      2.281 -0.658715  1.389699       A1  \n",
      "2      2.474 -0.634824  1.378332       A1  \n",
      "3      2.640 -0.657067  1.358426       A1  \n",
      "4      2.538 -0.687548  1.338520       A1  \n",
      "...      ...       ...       ...      ...  \n",
      "38729  8.237  0.993849 -1.949959       A6  \n",
      "38730  8.042  1.100121 -1.953868       A6  \n",
      "38731  9.164  1.319255 -1.959762       A6  \n",
      "38732  9.530  1.175912 -1.953868       A6  \n",
      "38733  8.828  0.918059 -1.949959       A6  \n",
      "\n",
      "[38734 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# 示例使用\n",
    "filename = './well_log_daqing_standardized.h5' # 请替换为您的文件名\n",
    "data, description = load_data_from_h5(filename)\n",
    "print(\"File Description:\", description)\n",
    "print(\"Data:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preproc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_process.py\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "# form constants import COLUMNS\n",
    "\n",
    "class DataStandardizer:\n",
    "    \"\"\"\n",
    "    数据标准化类，使用提前声明的 preproc 进行标准化。\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.scaler = preproc()\n",
    "        self.columns = columns\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        拟合标准化器。\n",
    "        \"\"\"\n",
    "        if self.columns is None:\n",
    "            self.columns = df.columns\n",
    "        self.scaler.fit(df[self.columns])\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"  \n",
    "        对数据进行标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before transforming.\")\n",
    "        # 标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.transform(df[self.columns]), columns=self.columns)\n",
    "        # 将标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df):\n",
    "        \"\"\" \n",
    "        对标准化后的数据进行反标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before inverse transforming.\")\n",
    "        # 反标准化指定的列\n",
    "        df_standardized = pd.DataFrame(self.scaler.inverse_transform(df[self.columns]), columns=self.columns)\n",
    "        # 将反标准化后的列替换原始数据框中的对应列\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"  \n",
    "        保存标准化器。\n",
    "        \"\"\"\n",
    "        joblib.dump(self.scaler, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\" \n",
    "        加载标准化器。\n",
    "        \"\"\"\n",
    "        self.scaler = joblib.load(filename)\n",
    "        self.fitted = True\n",
    "\n",
    "# 示例使用\n",
    "standardizer = DataStandardizer(columns= COLUMNS) # 指定需要标准化的列\n",
    "standardizer.fit(df) # 使用df数据进行标准化\n",
    "df_MinMaxScaler = standardizer.transform(df) # 标准化df数据\n",
    "\n",
    "# 保存标准化器\n",
    "standardizer.save('scaler_minmaxscalr.joblib')\n",
    "\n",
    "# # 加载标准化器\n",
    "# standardizer.load('scaler_minmaxscalr.joblib')\n",
    "\n",
    "# # 反标准化\n",
    "# df_original = standardizer.inverse_transform(df_MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_description = \"将标准化后的数据保存为.h5文件，以便后续使用。标准化器为MinMaxScaler。\"\n",
    "save_data_to_h5(df_standardized, 'well_log_daqing_MinMaxScaler.h5', file_description)\n",
    "print(\"数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为MinMaxScaler。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例使用\n",
    "filename = './well_log_daqing_MinMaxScaler.h5' # 请替换为您的文件名\n",
    "data, description = load_data_from_h5(filename)\n",
    "print(\"File Description:\", description)\n",
    "print(\"Data:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['most_frequent',\n",
       " 'sinkhorn',\n",
       " 'softimpute',\n",
       " 'EM',\n",
       " 'sklearn_missforest',\n",
       " 'miracle',\n",
       " 'nop',\n",
       " 'hyperimpute',\n",
       " 'mice',\n",
       " 'sklearn_ice',\n",
       " 'median',\n",
       " 'ice',\n",
       " 'missforest',\n",
       " 'miwae',\n",
       " 'mean',\n",
       " 'gain']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()\n",
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ice_plugin = \"custom_ice\"\n",
    "\n",
    "\n",
    "class NewPlugin(ImputerPlugin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        lr = LinearRegression()\n",
    "        self._model = IterativeImputer(\n",
    "            estimator=lr, max_iter=500, tol=1e-10, imputation_order=\"roman\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return custom_ice_plugin\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperparameter_space():\n",
    "        return []\n",
    "\n",
    "    def _fit(self, *args, **kwargs) -> \"NewPlugin\":\n",
    "        self._model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def _transform(self, *args, **kwargs):\n",
    "        return self._model.transform(*args, **kwargs)\n",
    "\n",
    "    def save(self) -> bytes:\n",
    "        raise NotImplemented(\"placeholder\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, buff: bytes) -> \"NewPlugin\":\n",
    "        raise NotImplemented(\"placeholder\")\n",
    "\n",
    "\n",
    "imputers.add(custom_ice_plugin, NewPlugin)\n",
    "\n",
    "assert imputers.get(custom_ice_plugin) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['most_frequent',\n",
       " 'sinkhorn',\n",
       " 'custom_ice',\n",
       " 'softimpute',\n",
       " 'EM',\n",
       " 'sklearn_missforest',\n",
       " 'miracle',\n",
       " 'nop',\n",
       " 'hyperimpute',\n",
       " 'mice',\n",
       " 'sklearn_ice',\n",
       " 'median',\n",
       " 'ice',\n",
       " 'missforest',\n",
       " 'miwae',\n",
       " 'mean',\n",
       " 'gain']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "preproc = MinMaxScaler()\n",
    "\n",
    "\n",
    "def dataset():\n",
    "    X = data\n",
    "\n",
    "    COLUMNS = ['DEPT', 'RMN-RMG', 'CAL', 'SP', 'GR', 'HAC', 'BHC', 'DEN']\n",
    "    \n",
    "    X = X[COLUMNS]\n",
    "\n",
    "    return train_test_split(X, test_size=0.2)\n",
    "\n",
    "\n",
    "def ampute(x, mechanism, p_miss):\n",
    "    x_simulated = simulate_nan(np.asarray(x), p_miss, mechanism)\n",
    "\n",
    "    mask = x_simulated[\"mask\"]\n",
    "    x_miss = x_simulated[\"X_incomp\"]\n",
    "\n",
    "    return pd.DataFrame(x), pd.DataFrame(x_miss), pd.DataFrame(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['most_frequent',\n",
    " 'sinkhorn',\n",
    " 'custom_ice',\n",
    " 'softimpute',\n",
    " 'EM',\n",
    " 'sklearn_missforest',\n",
    " 'miracle',\n",
    " 'nop',\n",
    " 'hyperimpute',\n",
    " 'mice',\n",
    " 'sklearn_ice',\n",
    " 'median',\n",
    " 'ice',\n",
    " 'missforest',\n",
    " 'miwae',\n",
    " 'mean',\n",
    " 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "headers = [\"Plugin\"]\n",
    "\n",
    "pct = 0.3\n",
    "\n",
    "mechanisms = [\"MAR\", \"MNAR\", \"MCAR\"]\n",
    "percentages = [pct]\n",
    "\n",
    "\n",
    "plugins = ['most_frequent',\n",
    " 'sinkhorn',\n",
    " 'softimpute',\n",
    " 'EM',\n",
    " 'sklearn_missforest',\n",
    " 'miracle',\n",
    " 'nop',\n",
    " 'hyperimpute',\n",
    " 'mice',\n",
    " 'sklearn_ice',\n",
    " 'median',\n",
    " 'ice',\n",
    " 'missforest',\n",
    " 'miwae',\n",
    " 'mean',\n",
    " 'gain']\n",
    "\n",
    "X_train, X_test = dataset()\n",
    "\n",
    "for ampute_mechanism in mechanisms:\n",
    "    for p_miss in percentages:\n",
    "        if ampute_mechanism not in datasets:\n",
    "            datasets[ampute_mechanism] = {}\n",
    "\n",
    "        headers.append(ampute_mechanism + \"-\" + str(p_miss))\n",
    "        datasets[ampute_mechanism][p_miss] = ampute(X_train, ampute_mechanism, p_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--- MAR ---'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0.3:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(           DEPT   RMN-RMG       CAL        SP        GR       HAC       BHC  \\\n",
       " 34159 -1.600958  0.011043 -0.701616  0.835695 -0.073063  0.272014  0.103910   \n",
       " 31675  1.385416 -1.863126  0.202941 -0.760403  1.026007 -0.656500 -0.193709   \n",
       " 13948 -1.670484 -0.623291  0.118906  0.609210 -0.015231  1.616928  1.557271   \n",
       " 18242  0.171494 -0.009552 -1.067971 -1.615043 -0.097443 -0.645246 -0.927806   \n",
       " 10671  0.086087 -0.463472 -1.310634  1.324207  0.403362 -0.624567 -0.424721   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 10588  0.050483  0.657735 -2.144375  1.013347 -0.006226 -0.569394 -0.355452   \n",
       " 12939  1.058981 -0.330014 -0.586422  0.369555 -0.157128 -0.075119 -0.265526   \n",
       " 34790 -1.330280  0.283725 -0.402300  0.608609  0.423595 -0.442953 -0.481820   \n",
       " 12900  1.042251 -0.148776 -0.248393  0.517979 -0.237198 -0.677459 -0.974008   \n",
       " 2925  -0.320315  1.025154  0.278479  0.198098 -0.242661 -0.836070 -0.710602   \n",
       " \n",
       "             DEN  \n",
       " 34159  1.518691  \n",
       " 31675  1.665266  \n",
       " 13948 -1.046359  \n",
       " 18242  0.052948  \n",
       " 10671  0.900985  \n",
       " ...         ...  \n",
       " 10588  0.021540  \n",
       " 12939 -0.418183  \n",
       " 34790  0.241401  \n",
       " 12900  0.733472  \n",
       " 2925  -0.575227  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "               0         1         2         3         4         5         6  \\\n",
       " 0     -1.600958  0.011043 -0.701616  0.835695 -0.073063  0.272014  0.103910   \n",
       " 1      1.385416       NaN  0.202941 -0.760403  1.026007 -0.656500 -0.193709   \n",
       " 2     -1.670484 -0.623291  0.118906  0.609210 -0.015231  1.616928  1.557271   \n",
       " 3      0.171494 -0.009552 -1.067971 -1.615043 -0.097443 -0.645246 -0.927806   \n",
       " 4      0.086087 -0.463472 -1.310634  1.324207  0.403362 -0.624567 -0.424721   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 30982       NaN  0.657735 -2.144375  1.013347 -0.006226 -0.569394 -0.355452   \n",
       " 30983  1.058981       NaN -0.586422  0.369555 -0.157128 -0.075119 -0.265526   \n",
       " 30984       NaN  0.283725 -0.402300  0.608609  0.423595 -0.442953 -0.481820   \n",
       " 30985       NaN -0.148776 -0.248393  0.517979 -0.237198 -0.677459 -0.974008   \n",
       " 30986 -0.320315       NaN  0.278479  0.198098       NaN -0.836070 -0.710602   \n",
       " \n",
       "               7  \n",
       " 0      1.518691  \n",
       " 1      1.665266  \n",
       " 2           NaN  \n",
       " 3           NaN  \n",
       " 4      0.900985  \n",
       " ...         ...  \n",
       " 30982  0.021540  \n",
       " 30983 -0.418183  \n",
       " 30984  0.241401  \n",
       " 30985  0.733472  \n",
       " 30986 -0.575227  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "          0    1    2    3    4    5    6    7\n",
       " 0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ...    ...  ...  ...  ...  ...  ...  ...  ...\n",
       " 30982  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 30983  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 30984  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 30985  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 30986  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " \n",
       " [30987 rows x 8 columns])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--- MNAR ---'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0.3:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(           DEPT   RMN-RMG       CAL        SP        GR       HAC       BHC  \\\n",
       " 34159 -1.600958  0.011043 -0.701616  0.835695 -0.073063  0.272014  0.103910   \n",
       " 31675  1.385416 -1.863126  0.202941 -0.760403  1.026007 -0.656500 -0.193709   \n",
       " 13948 -1.670484 -0.623291  0.118906  0.609210 -0.015231  1.616928  1.557271   \n",
       " 18242  0.171494 -0.009552 -1.067971 -1.615043 -0.097443 -0.645246 -0.927806   \n",
       " 10671  0.086087 -0.463472 -1.310634  1.324207  0.403362 -0.624567 -0.424721   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 10588  0.050483  0.657735 -2.144375  1.013347 -0.006226 -0.569394 -0.355452   \n",
       " 12939  1.058981 -0.330014 -0.586422  0.369555 -0.157128 -0.075119 -0.265526   \n",
       " 34790 -1.330280  0.283725 -0.402300  0.608609  0.423595 -0.442953 -0.481820   \n",
       " 12900  1.042251 -0.148776 -0.248393  0.517979 -0.237198 -0.677459 -0.974008   \n",
       " 2925  -0.320315  1.025154  0.278479  0.198098 -0.242661 -0.836070 -0.710602   \n",
       " \n",
       "             DEN  \n",
       " 34159  1.518691  \n",
       " 31675  1.665266  \n",
       " 13948 -1.046359  \n",
       " 18242  0.052948  \n",
       " 10671  0.900985  \n",
       " ...         ...  \n",
       " 10588  0.021540  \n",
       " 12939 -0.418183  \n",
       " 34790  0.241401  \n",
       " 12900  0.733472  \n",
       " 2925  -0.575227  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "               0         1         2         3         4         5         6  \\\n",
       " 0           NaN  0.011043       NaN       NaN -0.073063  0.272014  0.103910   \n",
       " 1      1.385416 -1.863126  0.202941 -0.760403  1.026007 -0.656500       NaN   \n",
       " 2           NaN       NaN  0.118906  0.609210       NaN  1.616928  1.557271   \n",
       " 3      0.171494 -0.009552 -1.067971       NaN -0.097443 -0.645246       NaN   \n",
       " 4      0.086087 -0.463472 -1.310634  1.324207  0.403362 -0.624567       NaN   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 30982  0.050483  0.657735       NaN       NaN -0.006226       NaN -0.355452   \n",
       " 30983       NaN -0.330014 -0.586422  0.369555       NaN -0.075119       NaN   \n",
       " 30984 -1.330280  0.283725       NaN  0.608609  0.423595 -0.442953       NaN   \n",
       " 30985  1.042251 -0.148776 -0.248393  0.517979       NaN -0.677459       NaN   \n",
       " 30986 -0.320315  1.025154  0.278479       NaN -0.242661 -0.836070 -0.710602   \n",
       " \n",
       "               7  \n",
       " 0      1.518691  \n",
       " 1           NaN  \n",
       " 2     -1.046359  \n",
       " 3      0.052948  \n",
       " 4           NaN  \n",
       " ...         ...  \n",
       " 30982  0.021540  \n",
       " 30983       NaN  \n",
       " 30984  0.241401  \n",
       " 30985       NaN  \n",
       " 30986       NaN  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "          0    1    2    3    4    5    6    7\n",
       " 0      1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       " 1      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0\n",
       " 2      1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 3      0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0\n",
       " 4      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0\n",
       " ...    ...  ...  ...  ...  ...  ...  ...  ...\n",
       " 30982  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0\n",
       " 30983  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0\n",
       " 30984  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0\n",
       " 30985  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0\n",
       " 30986  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       " \n",
       " [30987 rows x 8 columns])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--- MCAR ---'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0.3:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(           DEPT   RMN-RMG       CAL        SP        GR       HAC       BHC  \\\n",
       " 34159 -1.600958  0.011043 -0.701616  0.835695 -0.073063  0.272014  0.103910   \n",
       " 31675  1.385416 -1.863126  0.202941 -0.760403  1.026007 -0.656500 -0.193709   \n",
       " 13948 -1.670484 -0.623291  0.118906  0.609210 -0.015231  1.616928  1.557271   \n",
       " 18242  0.171494 -0.009552 -1.067971 -1.615043 -0.097443 -0.645246 -0.927806   \n",
       " 10671  0.086087 -0.463472 -1.310634  1.324207  0.403362 -0.624567 -0.424721   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 10588  0.050483  0.657735 -2.144375  1.013347 -0.006226 -0.569394 -0.355452   \n",
       " 12939  1.058981 -0.330014 -0.586422  0.369555 -0.157128 -0.075119 -0.265526   \n",
       " 34790 -1.330280  0.283725 -0.402300  0.608609  0.423595 -0.442953 -0.481820   \n",
       " 12900  1.042251 -0.148776 -0.248393  0.517979 -0.237198 -0.677459 -0.974008   \n",
       " 2925  -0.320315  1.025154  0.278479  0.198098 -0.242661 -0.836070 -0.710602   \n",
       " \n",
       "             DEN  \n",
       " 34159  1.518691  \n",
       " 31675  1.665266  \n",
       " 13948 -1.046359  \n",
       " 18242  0.052948  \n",
       " 10671  0.900985  \n",
       " ...         ...  \n",
       " 10588  0.021540  \n",
       " 12939 -0.418183  \n",
       " 34790  0.241401  \n",
       " 12900  0.733472  \n",
       " 2925  -0.575227  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "               0         1         2         3         4         5         6  \\\n",
       " 0           NaN       NaN -0.701616  0.835695 -0.073063  0.272014       NaN   \n",
       " 1           NaN -1.863126  0.202941       NaN  1.026007       NaN -0.193709   \n",
       " 2           NaN -0.623291  0.118906       NaN -0.015231  1.616928       NaN   \n",
       " 3      0.171494 -0.009552 -1.067971 -1.615043 -0.097443 -0.645246 -0.927806   \n",
       " 4      0.086087 -0.463472       NaN  1.324207       NaN -0.624567       NaN   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 30982  0.050483  0.657735 -2.144375  1.013347       NaN       NaN -0.355452   \n",
       " 30983  1.058981 -0.330014       NaN  0.369555 -0.157128 -0.075119 -0.265526   \n",
       " 30984       NaN  0.283725 -0.402300  0.608609       NaN -0.442953 -0.481820   \n",
       " 30985       NaN       NaN -0.248393  0.517979       NaN -0.677459 -0.974008   \n",
       " 30986 -0.320315       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       " \n",
       "               7  \n",
       " 0      1.518691  \n",
       " 1      1.665266  \n",
       " 2     -1.046359  \n",
       " 3      0.052948  \n",
       " 4      0.900985  \n",
       " ...         ...  \n",
       " 30982  0.021540  \n",
       " 30983 -0.418183  \n",
       " 30984  0.241401  \n",
       " 30985       NaN  \n",
       " 30986       NaN  \n",
       " \n",
       " [30987 rows x 8 columns],\n",
       "          0    1    2    3    4    5    6    7\n",
       " 0      1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       " 1      1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n",
       " 2      1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0\n",
       " 3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 4      0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0\n",
       " ...    ...  ...  ...  ...  ...  ...  ...  ...\n",
       " 30982  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       " 30983  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 30984  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 30985  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0\n",
       " 30986  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " \n",
       " [30987 rows x 8 columns])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# 在这里添加打印datasets的代码\n",
    "for key, value in datasets.items():\n",
    "    display(f\"--- {key} ---\") # 使用分隔符和标题\n",
    "    for sub_key, sub_value in value.items():\n",
    "        display(f\"{sub_key}:\")\n",
    "        display(sub_value)\n",
    "    display(\"------\") # 使用分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [1:10:26<2:49:36, 925.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Desktop\\插补实验\\hyperimpute\\hyperimpute\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [1:55:45<00:00, 434.08s/it] \n"
     ]
    }
   ],
   "source": [
    "from hyperimpute import logger\n",
    "\n",
    "results = []\n",
    "duration = []\n",
    "\n",
    "for plugin in tqdm(plugins):\n",
    "    plugin_results = [plugin]\n",
    "    plugin_duration = [plugin]\n",
    "\n",
    "    for ampute_mechanism in mechanisms:\n",
    "        for p_miss in percentages:\n",
    "            print(f\"-------Running {plugin} on {ampute_mechanism} with {p_miss} missing values---------\")\n",
    "            # 动态开启debug模式，测试每个模型的训练时间和细节\n",
    "            logger.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "            \n",
    "            ctx = imputers.get(plugin)\n",
    "            \n",
    "            x, x_miss, mask = datasets[ampute_mechanism][p_miss]\n",
    "\n",
    "            start = time.time() * 1000\n",
    "            x_imp = ctx.fit_transform(x_miss)\n",
    "\n",
    "            plugin_duration.append(round(time.time() * 1000 - start, 4))\n",
    "            plugin_results.append(RMSE(x_imp.values, x.values, mask.values))\n",
    "            print(f\"-------{plugin} on {ampute_mechanism} with {p_miss} missing values finished---------\")\n",
    "\n",
    "    results.append(plugin_results)\n",
    "    duration.append(plugin_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Plugin            </th><th style=\"text-align: right;\">   MAR-0.3</th><th style=\"text-align: right;\">  MNAR-0.3</th><th style=\"text-align: right;\">  MCAR-0.3</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>most_frequent     </td><td style=\"text-align: right;\">  1.01982 </td><td style=\"text-align: right;\">  1.01598 </td><td style=\"text-align: right;\">  1.07754 </td></tr>\n",
       "<tr><td>sinkhorn          </td><td style=\"text-align: right;\">  0.899713</td><td style=\"text-align: right;\">  0.861064</td><td style=\"text-align: right;\">  0.917585</td></tr>\n",
       "<tr><td>softimpute        </td><td style=\"text-align: right;\">  1.29684 </td><td style=\"text-align: right;\">  1.50383 </td><td style=\"text-align: right;\">  0.917716</td></tr>\n",
       "<tr><td>EM                </td><td style=\"text-align: right;\">  0.731373</td><td style=\"text-align: right;\">  0.746211</td><td style=\"text-align: right;\">  0.756631</td></tr>\n",
       "<tr><td>sklearn_missforest</td><td style=\"text-align: right;\">  0.705665</td><td style=\"text-align: right;\">  0.728864</td><td style=\"text-align: right;\">  0.799713</td></tr>\n",
       "<tr><td>miracle           </td><td style=\"text-align: right;\">  0.68799 </td><td style=\"text-align: right;\">  1.38333 </td><td style=\"text-align: right;\">  0.793778</td></tr>\n",
       "<tr><td>nop               </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>hyperimpute       </td><td style=\"text-align: right;\">  0.534954</td><td style=\"text-align: right;\">  0.626855</td><td style=\"text-align: right;\">  0.653863</td></tr>\n",
       "<tr><td>mice              </td><td style=\"text-align: right;\">  1.0951  </td><td style=\"text-align: right;\">  1.07816 </td><td style=\"text-align: right;\">  1.06903 </td></tr>\n",
       "<tr><td>sklearn_ice       </td><td style=\"text-align: right;\">  0.730121</td><td style=\"text-align: right;\">  0.929051</td><td style=\"text-align: right;\">  0.854112</td></tr>\n",
       "<tr><td>median            </td><td style=\"text-align: right;\">  0.986769</td><td style=\"text-align: right;\">  0.965045</td><td style=\"text-align: right;\">  1.02954 </td></tr>\n",
       "<tr><td>ice               </td><td style=\"text-align: right;\">  0.721275</td><td style=\"text-align: right;\">  0.788141</td><td style=\"text-align: right;\">  0.787818</td></tr>\n",
       "<tr><td>missforest        </td><td style=\"text-align: right;\">  0.716245</td><td style=\"text-align: right;\">  0.704552</td><td style=\"text-align: right;\">  0.760177</td></tr>\n",
       "<tr><td>miwae             </td><td style=\"text-align: right;\">  0.911797</td><td style=\"text-align: right;\">  0.891459</td><td style=\"text-align: right;\">  0.926765</td></tr>\n",
       "<tr><td>mean              </td><td style=\"text-align: right;\">  1.00102 </td><td style=\"text-align: right;\">  0.960574</td><td style=\"text-align: right;\">  1.01132 </td></tr>\n",
       "<tr><td>gain              </td><td style=\"text-align: right;\">  0.941303</td><td style=\"text-align: right;\">  1.4396  </td><td style=\"text-align: right;\">  1.13961 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Plugin            </th><th style=\"text-align: right;\">    MAR-0.3</th><th style=\"text-align: right;\">        MNAR-0.3</th><th style=\"text-align: right;\">   MCAR-0.3</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>most_frequent     </td><td style=\"text-align: right;\">    25.0005</td><td style=\"text-align: right;\">    19.9939     </td><td style=\"text-align: right;\">    19.0002</td></tr>\n",
       "<tr><td>sinkhorn          </td><td style=\"text-align: right;\">351510     </td><td style=\"text-align: right;\">348465          </td><td style=\"text-align: right;\">342343     </td></tr>\n",
       "<tr><td>softimpute        </td><td style=\"text-align: right;\">145530     </td><td style=\"text-align: right;\">143592          </td><td style=\"text-align: right;\">138369     </td></tr>\n",
       "<tr><td>EM                </td><td style=\"text-align: right;\">203784     </td><td style=\"text-align: right;\">     1.96459e+06</td><td style=\"text-align: right;\">357597     </td></tr>\n",
       "<tr><td>sklearn_missforest</td><td style=\"text-align: right;\">  2399.51  </td><td style=\"text-align: right;\">114315          </td><td style=\"text-align: right;\">113232     </td></tr>\n",
       "<tr><td>miracle           </td><td style=\"text-align: right;\">124503     </td><td style=\"text-align: right;\">154919          </td><td style=\"text-align: right;\">167396     </td></tr>\n",
       "<tr><td>nop               </td><td style=\"text-align: right;\">     0.5105</td><td style=\"text-align: right;\">     0          </td><td style=\"text-align: right;\">     0     </td></tr>\n",
       "<tr><td>hyperimpute       </td><td style=\"text-align: right;\"> 18448.2   </td><td style=\"text-align: right;\"> 32396.5        </td><td style=\"text-align: right;\"> 31318.4   </td></tr>\n",
       "<tr><td>mice              </td><td style=\"text-align: right;\">  9683.53  </td><td style=\"text-align: right;\"> 12874.5        </td><td style=\"text-align: right;\"> 12935.4   </td></tr>\n",
       "<tr><td>sklearn_ice       </td><td style=\"text-align: right;\">   328.017 </td><td style=\"text-align: right;\">  5987.63       </td><td style=\"text-align: right;\">  3408.72  </td></tr>\n",
       "<tr><td>median            </td><td style=\"text-align: right;\">    35.9998</td><td style=\"text-align: right;\">    27.9963     </td><td style=\"text-align: right;\">    27.9963</td></tr>\n",
       "<tr><td>ice               </td><td style=\"text-align: right;\">  2171.68  </td><td style=\"text-align: right;\">  3151.57       </td><td style=\"text-align: right;\">  5616.77  </td></tr>\n",
       "<tr><td>missforest        </td><td style=\"text-align: right;\"> 58088.8   </td><td style=\"text-align: right;\"> 47267.8        </td><td style=\"text-align: right;\"> 71994.7   </td></tr>\n",
       "<tr><td>miwae             </td><td style=\"text-align: right;\">661311     </td><td style=\"text-align: right;\">642392          </td><td style=\"text-align: right;\">605070     </td></tr>\n",
       "<tr><td>mean              </td><td style=\"text-align: right;\">    14.9993</td><td style=\"text-align: right;\">    12.0012     </td><td style=\"text-align: right;\">    11.0022</td></tr>\n",
       "<tr><td>gain              </td><td style=\"text-align: right;\">  5557.15  </td><td style=\"text-align: right;\">  5062.23       </td><td style=\"text-align: right;\">  5201.89  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))\n",
    "display(HTML(tabulate.tabulate(duration, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "毫秒为单位的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化缩放器的代码，使其更加简洁，可扩展，可更换缩放器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "class DataStandardizer:\n",
    "    \"\"\"\n",
    "    数据标准化类，支持多种标准化方法。\n",
    "    \"\"\"\n",
    "    def __init__(self, scaler_type='standard', columns=None):\n",
    "        self.scaler_type = scaler_type\n",
    "        self.scaler = None\n",
    "        self.columns = columns\n",
    "        self.fitted = False\n",
    "\n",
    "    def _get_scaler(self):\n",
    "        if self.scaler_type == 'standard':\n",
    "            return StandardScaler()\n",
    "        elif self.scaler_type == 'minmax':\n",
    "            return MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scaler type: {self.scaler_type}\")\n",
    "\n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        拟合标准化器。\n",
    "        \"\"\"\n",
    "        if self.columns is None:\n",
    "            self.columns = df.columns\n",
    "        self.scaler = self._get_scaler()\n",
    "        self.scaler.fit(df[self.columns])\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"  \n",
    "        对数据进行标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before transforming.\")\n",
    "        df_standardized = pd.DataFrame(self.scaler.transform(df[self.columns]), columns=self.columns)\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df):\n",
    "        \"\"\" \n",
    "        对标准化后的数据进行反标准化。\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler is not fitted yet. Call 'fit' with appropriate data before inverse transforming.\")\n",
    "        df_standardized = pd.DataFrame(self.scaler.inverse_transform(df[self.columns]), columns=self.columns)\n",
    "        for col in self.columns:\n",
    "            df[col] = df_standardized[col]\n",
    "        return df\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"  \n",
    "        保存标准化器。\n",
    "        \"\"\"\n",
    "        joblib.dump(self, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\" \n",
    "        加载标准化器。\n",
    "        \"\"\"\n",
    "        loaded_obj = joblib.load(filename)\n",
    "        self.scaler = loaded_obj.scaler\n",
    "        self.scaler_type = loaded_obj.scaler_type\n",
    "        self.columns = loaded_obj.columns\n",
    "        self.fitted = loaded_obj.fitted\n",
    "\n",
    "# # 示例使用\n",
    "# standardizer = DataStandardizer(columns=COLUMNS) # 指定需要标准化的列\n",
    "# standardizer.fit(df) # 使用df数据进行标准化\n",
    "# df_standardized = standardizer.transform(df) # 标准化df数据\n",
    "\n",
    "# # 保存标准化器\n",
    "# standardizer.save('scaler.joblib')\n",
    "\n",
    "# # 加载标准化器\n",
    "# standardizer.load('scaler.joblib')\n",
    "\n",
    "# # 反标准化\n",
    "# df_original = standardizer.inverse_transform(df_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分过程可以使用skrlearn的pipeline来进行标准数据处理流，而且更简单，更方便，可读性更强，内容更完善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_description = \"将标准化后的数据保存为.h5文件，以便后续使用。标准化器为MinMaxScaler。\"\n",
    "save_data_to_h5(df_standardized, 'well_log_daqing_MinMaxScaler.h5', file_description)\n",
    "print(\"数据已保存为well_log_daqing_standardized.h5。还有一个标准化器scaler.joblib。使用的标准化器为MinMaxScaler。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例使用\n",
    "filename = './well_log_daqing_MinMaxScaler.h5' # 请替换为您的文件名\n",
    "data, description = load_data_from_h5(filename)\n",
    "print(\"File Description:\", description)\n",
    "print(\"Data:\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
